# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1st9ujjSm__-pEplNk2wqotETrPY_YkEk
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset
import numpy as np
import cv2
import PIL
from PIL import Image
import torchvision.transforms
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torchvision import transforms

from google.colab import drive

drive.mount('/content/drive/')

!unzip /content/drive/MyDrive/194/ibug_300W_large_face_landmark_dataset.zip -d /content/drive/MyDrive/194/ibug_300W_large_face_landmark_dataset

import xml.etree.ElementTree as ET 
import numpy as np
import os 

tree = ET.parse('/content/drive/MyDrive/194/ibug_300W_large_face_landmark_dataset/labels_ibug_300W_train.xml')
root = tree.getroot()
root_dir = 'ibug_300W_large_face_landmark_dataset'

bboxes = [] # face bounding box used to crop the image
landmarks = [] # the facial keypoints/landmarks for the whole training dataset
img_filenames = [] # the image names for the whole dataset

for filename in root[2]:
	img_filenames.append(os.path.join(root_dir, filename.attrib['file']))
	box = filename[0].attrib
	# x, y for the top left corner of the box, w, h for box width and height
	bboxes.append([box['left'], box['top'], box['width'], box['height']]) 

	landmark = []
	for num in range(68):
		x_coordinate = int(filename[0][num].attrib['x'])
		y_coordinate = int(filename[0][num].attrib['y'])
		landmark.append([x_coordinate, y_coordinate])
	landmarks.append(landmark)

landmarks = np.array(landmarks).astype('float32')     
bboxes = np.array(bboxes).astype('float32')

from google.colab import drive
drive.mount('/content/drive')

img_filenames[45]

import matplotlib.pyplot as plt
image = plt.imread("/content/drive/MyDrive/194/" + img_filenames[45])
plt.imshow(image)
plt.show()

from torch.utils.data import Dataset
from torchvision import transforms
import imgaug.augmenters as iaa


class TrainDataset(Dataset):
    def __init__(self):
        
        self.image_paths = img_filenames
        self.label_paths = landmarks
        self.bound_boxes = bboxes
        # TODO: Iterate over files in dataset path, add image and label paths to lists.
        # TODO: Randomly split into train and test partitions. Make sure the random split is the same each time.

        assert len(self.image_paths) == len(self.label_paths)

    def __getitem__(self, index: int):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        bbox_path = self.bound_boxes[index]

        img = cv2.imread("/content/drive/MyDrive/194/" + image_path)
        
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        plt.imshow(img, cmap = "gray")


        # img = ((img.astype(np.float32))/255) - 0.5

        X, Y, W, H = bbox_path

        if X < 0:
          X = 0

        if Y < 0:
          Y = 0

        # for x, subtract the bbox left value, divide by the width of the bounding box; for y, subtract bbox top and divide by the height

        img = img[int(Y):int(Y+H), int(X):int(X+W)]


        # for i in range(len(label_path)):
        #   x, y = label_path[i]
        #   x = (x - X) / W
        #   y = (y - Y) / H
        #   label_path[i] = x, y
        label_path =(label_path - np.array([X,Y]))
        # print(label_path)


        label_path = label_path.reshape((1, 68, 2))
        # print(img.shape)

        # print(label_path_resize)
        
        seq = iaa.SomeOf(2, 
                [iaa.AdditiveGaussianNoise(scale=0.05*255),
                iaa.Affine(translate_px={"x": (-10, 10)}),
                iaa.Affine(rotate = (-15, 15)),
                iaa.Fliplr(1)#,
                # iaa.Sharpen(alpha=0.5),
                ])
        
        images_aug, points_aug = seq(images=img, keypoints=label_path)
        # print(points_aug)

        resize = iaa.Resize({"height": 224, "width": 224})

        img_resize, label_path_resize = resize(images=images_aug, keypoints=points_aug)


        label_path_resize = np.divide(label_path_resize, [224, 224])


        
        label_path = label_path_resize.reshape((68, 2))

        # print(label_path)
        # label_path = label_path_resize.reshape((68, 2))


        # image_path = img_resize.reshape(img_resize.shape[0], img_resize.shape[1], 1)
        image_path = img_resize.reshape(img_resize.shape[0], img_resize.shape[1], 1)
        image_path = image_path.transpose((2, 0, 1))
        image_path = ((image_path.astype(np.float32))/255) - 0.5

        image_tensor = torch.tensor(image_path).to(torch.float32)
        label_tensor = torch.tensor(label_path).to(torch.float32)
        label_tensor = torch.reshape(label_tensor, (136, 1))
        return image_tensor, label_tensor
        

    def __len__(self) -> int:
        return len(self.image_paths)

train_data = TrainDataset()
train_set = torch.utils.data.Subset(train_data,np.arange(0,500))
# train_set = torch.utils.data.Subset(train_data,np.arange(0,1))

validation_set = torch.utils.data.Subset(train_data,np.arange(5000,6666))

len(train_set)
# len(validation_set)

from torch.utils.data import DataLoader

# train_loader = DataLoader(train_set, batch_size = 1, num_workers=2)
train_loader = DataLoader(train_set, batch_size = 32)
validation_loader = DataLoader(validation_set, batch_size = 32)

plt.figure(figsize=(6,8))

i = 8 #batch number #(1-24)
# j = 1 #face in batch (1-4)
for i in range(10):
  train_loader_iter = next(iter(train_loader))
  face = train_loader_iter[0][i].numpy()
  print(face.shape)
  face = face.reshape((face.shape[1], face.shape[2], 1))
  implot = plt.imshow(face[:,:,0], cmap='gray')

  xs = []
  ys = []
  for pt in train_loader_iter[1][i].numpy():
    # print("pt", pt)
    xs.append(pt[0]*224)
    ys.append(pt[1]*224)
          
          
  plt.scatter(np.asarray(xs),np.asarray(ys), c = 'r', s= 6)


  plt.show()

from torchvision.models import resnet18
net = resnet18(pretrained = True)
net = net.cuda()

import torch.nn as nn
#modify output feature number
net.fc = nn.Linear(512, 68*2)
net.fc = net.fc.cuda()
#modify input feature number
net.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
net.conv1 = net.conv1.cuda()
print(net)

criterion = nn.MSELoss()  # nn.MSELoss() nn.L1Loss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)

import os
save_dir = "/content/drive/MyDrive/194/chkpts"
os.makedirs(save_dir, exist_ok=True)

import tqdm
from torch.utils.tensorboard import SummaryWriter

# tb_writer = SummaryWriter(log_dir=save_dir)

# state_dict = torch.load(os.path.join(save_dir, 'checkpoint_big.pt'))
# net.load_state_dict(state_dict)

# loop over the dataset multiple times
num_epochs = 10
loss_values = []
valid_loss_values = []

for epoch in range(num_epochs):  

    # running_losses = []
    running_loss = 0.0
    valid_running_loss = 0.0
    progress_bar = tqdm.tqdm(train_loader, position = 0, leave = True)
    valid_progress_bar = tqdm.tqdm(validation_loader, position = 0, leave = True)
    net.train()
    
    for i, data in enumerate(progress_bar):

        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        inputs = inputs.cuda()
        labels = labels.cuda()

        print(labels.shape)
        
        # zero the parameter gradients
        net.zero_grad()
        
        # forward pass
        outputs = net(inputs)
        
        # compute loss
        loss = criterion(outputs, labels[:,:,0])

        # backward pass
        loss.backward()

        # update network parameters
        optimizer.step()

        progress_bar.set_description(f"Train Loss: {loss}")

        # print statistics
        # running_losses.append(loss.item())
        print("epoch", epoch)
        
        loss = loss.detach()

        running_loss += loss.cpu().detach().numpy()


        
        # global_step = epoch * len(train_loader) + i
        # tb_writer.add_scalar("training loss", loss.item(), global_step)
        # progress_bar.set_description(f"Loss: {loss}")

    loss_values.append(running_loss / (i + 1))

    
    net.eval()
  #   running_losses = []

  #   net.train()
    for i, data in enumerate(valid_progress_bar):
      inputs, labels = data
      inputs = inputs.cuda()
      labels = labels.cuda()
            
  #           # calculate outputs
      outputs = net(inputs)
  # #             print(inputs.size)

  #           # compute loss
      loss = criterion(outputs, labels[:,:,0])
  # #             print(loss)
  #     loss = loss.detach().cpu().numpy()
      valid_progress_bar.set_description(f"Validation Loss: {loss}")

  #           # print statistics
  #     running_losses.append(loss.item())

      valid_running_loss += loss.cpu().detach().numpy()
  #     # valid_running_loss = valid_running_loss.cpu().detach().numpy()


    valid_loss_values.append((valid_running_loss / (i+1)))

      
# state_dict = torch.load(os.path.join(save_dir, 'checkpoint.pt'))
# net.load_state_dict(state_dict)

  

print('Finished Training')

plt.plot(loss_values, label='Train')
plt.plot(valid_loss_values, label='Validation')

plt.ylabel('MSE Loss')
plt.xlabel('Epoch #')

# /content/ibug_facepts_mse.jpg

tree = ET.parse('/content/drive/MyDrive/194/labels_ibug_300W_test_parsed.xml')
root = tree.getroot()
root_dir = 'ibug_300W_large_face_landmark_dataset'

bboxes = [] # face bounding box used to crop the image
img_filenames = [] # the image names for the whole dataset

for filename in root[2]:
	img_filenames.append(os.path.join(root_dir, filename.attrib['file']))
	box = filename[0].attrib
	# x, y for the top left corner of the box, w, h for box width and height
	bboxes.append([box['left'], box['top'], box['width'], box['height']]) 
     
bboxes = np.array(bboxes).astype('float32')



class TestDataset(Dataset):
    def __init__(self):
        
        self.image_paths = img_filenames
        self.bound_boxes = bboxes
        # TODO: Iterate over files in dataset path, add image and label paths to lists.
        # TODO: Randomly split into train and test partitions. Make sure the random split is the same each time.

        assert len(self.image_paths) == len(self.bound_boxes)

    def __getitem__(self, index: int):
        image_path = self.image_paths[index]
        bbox_path = self.bound_boxes[index]

        img = cv2.imread("/content/drive/MyDrive/194/" + image_path)
        

        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        X, Y, W, H = bbox_path

        if X < 0:
          X = 0

        if Y < 0:
          Y = 0

        img = img[int(Y):int(Y+H), int(X):int(X+W)]

        resize = iaa.Resize({"height": 224, "width": 224})

        img_resize = resize(images=img)

        image_path = img_resize.reshape(img_resize.shape[0], img_resize.shape[1], 1)
        image_path = image_path.transpose((2, 0, 1))
        image_path = ((image_path.astype(np.float32))/255) - 0.5

        image_tensor = torch.tensor(image_path).to(torch.float32)
        return image_tensor

    def __len__(self) -> int:
        return len(self.image_paths)

from torch.utils.data import DataLoader

test_data = TestDataset()
test_small_set = torch.utils.data.Subset(test_data,np.arange(0,10))
test_loader = DataLoader(test_small_set, batch_size = 1, num_workers=2)

print(next(iter(test_loader)))

plt.figure(figsize=(6,8))

i = 0 #batch number #(1-24)
# j = 1 #face in batch (1-4)
# for i in range(10):
test_loader_iter = next(iter(test_loader))
face = test_loader_iter[i].numpy()
print(face.shape)
implot = plt.imshow(face[0,:,:], cmap='gray')

plt.show()

len(test_loader)

save_dir = "/content/drive/MyDrive/194/"

import csv
from csv import writer
plt.figure(figsize=(3,4))

i = 1

plt.figure(figsize=(6,8))

i = 8 #batch number #(1-24)
# j = 1 #face in batch (1-4)
for i in range(5, 10):
  face = cv2.imread("/content/drive/MyDrive/194/" + img_filenames[i])
  print(face.shape)
  implot = plt.imshow(face[:,:,0], cmap = "gray")
  xs = []
  ys = []
  for pt in preds[i]:
      xs.append(pt[0])
      ys.append(pt[1])

  print(xs)
  plt.scatter(xs, ys, c = 'r', s= 10)


  plt.show()



#test loop
import csv
from csv import writer
with torch.no_grad():
    
    # initialize a list to store our predictions
  preds = []

  # with open('/content/drive/MyDrive/194/predictions.csv', 'w') as f:
    # create the csv writer
    # writer_obj = csv.writer(f)
  
  #change loader to pass in custom images
  for i, data in enumerate(test_loader):
        inputs = data
        # inputs = inputs.cuda()

        # print(inputs.shape)

        # calculate outputs by running images through the network
        outputs = net(inputs)

        # print(outputs)
        outputs = outputs.reshape((68,2))

        # print(outputs)


        orig_img = cv2.imread("/content/drive/MyDrive/194/" + img_filenames[i])
        # print(orig_img.shape)

        # print(outputs)
        # garbage_img , keypoints_resize = resize(images= inputs, keypoints = outputs)
        # outputs = outputs.cpu().detach().numpy()
        # print(outputs)

#         outputs = outputs.reshape((68,2))
        default = np.zeros((224, 224))

        X, Y, W, H = bboxes[i]

        if X < 0:
          X = 0

        if Y < 0:
          Y = 0


        resize = iaa.Resize({"height": H, "width": W})
        _ , keypoints_resize = resize(images= default, keypoints = outputs)
        keypoints_resize = keypoints_resize.detach().cpu().numpy()
        outputs = keypoints_resize + np.array([X,Y])

        print(outputs.shape)

#         # print(outputs)
#         garbage_img , keypoints_resize = resize(images= inputs, keypoints = outputs)

#         outputs = np.multiply(outputs, np.array([W, H])) + np.array([X,Y])

#         # with open('/content/drive/MyDrive/194/predictions.csv', 'w') as f:
#         #     # create the csv writer
#         #     writer_obj = csv.writer(f)



#         # for pt in outputs:
#         #   x = [pt[0]]
#         #   y = [pt[1]]
#         #   print(x, y)
#         #   writer_obj.writerow(x)
#         #   writer_obj.writerow(y)
              
              
              
#               # f.close()

#         # print(outputs)

#         # outputs = outputs.reshape((1, 68, 2))

#         # resize = iaa.Resize({"height": orig_img.shape[1], "width": orig_img.shape[0]})


#         print(outputs)
#         # inputs = inputs.cpu().detach().numpy()
#         # garbage_img , keypoints_resize = resize(images= inputs, keypoints = outputs)
        
#         # outputs = outputs.reshape((68,2))

#         # print(outputs.shape)
#         preds.append(outputs)
        
# # print(len(preds))

#visualize on test images
from imgaug.augmentables.kps import Keypoint
# plt.figure(figsize=(3,4))


i = 1

plt.figure(figsize=(6,8))

i = 8 #batch number #(1-24)
# j = 1 #face in batch (1-4)
for i in range(0, 5):
  pts = outputs[i].reshape((68,2))
  face = cv2.imread("/content/drive/MyDrive/194/" + img_filenames[i])
  default = np.zeros((224, 224))
  # print(type(face))
  # face = face.reshape(face.shape[0], face.shape[1], 1)
  X, Y, W, H = bboxes[i]

  if X < 0:
    X = 0

  if Y < 0:
    Y = 0
  # outputs = np.multiply(pts, np.array([224, 224])) #np.array([W, H])+ np.array([X,Y])
  print(outputs)
  resize = iaa.Resize({"height": H, "width": W})
  _ , keypoints_resize = resize(images= face, keypoints = outputs)
  keypoints_resize = keypoints_resize.detach().cpu().numpy()
  outputs = keypoints_resize + np.array([X,Y])

  print(outputs.shape)
  # outputs = outputs.detach().cpu().numpy()
  # outputs = outputs.reshape((1, 68, 2))
  # pts = pts.reshape((1, 68, 2))
  # resize = iaa.Resize({"height": H, "width": W})
  # _ , keypoints_resize = resize(images= face, keypoints = outputs)
# 
  # implot = plt.imshow(face[:,:,0], cmap = "gray")
  # xs = []
  # ys = []
  # for pt in outputs:
  #     xs.append(pt[0])
  #     ys.append(pt[1])

  # # print(xs)
  # plt.scatter(xs, ys, c = 'r', s= 10)


  # plt.show()

#for running model on my own images
tree = ET.parse('/content/drive/MyDrive/194/custom_data.xml')
root = tree.getroot()
root_dir = 'custom'

bboxes = [] # face bounding box used to crop the image
img_filenames = [] # the image names for the whole dataset

for filename in root[2]:
	img_filenames.append(os.path.join(root_dir, filename.attrib['file']))
	box = filename[0].attrib
	# x, y for the top left corner of the box, w, h for box width and height
	bboxes.append([box['left'], box['top'], box['width'], box['height']]) 
     
bboxes = np.array(bboxes).astype('float32')

class CustomDataset(Dataset):
    def __init__(self):
        
        self.image_paths = img_filenames
        self.bound_boxes = bboxes
        # TODO: Iterate over files in dataset path, add image and label paths to lists.
        # TODO: Randomly split into train and test partitions. Make sure the random split is the same each time.

        assert len(self.image_paths) == len(self.bound_boxes)

    def __getitem__(self, index: int):
        image_path = self.image_paths[index]
        bbox_path = self.bound_boxes[index]

        img = cv2.imread("/content/drive/MyDrive/194/" + image_path)
        

        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        X, Y, W, H = bbox_path

        if X < 0:
          X = 0

        if Y < 0:
          Y = 0

        img = img[int(Y):int(Y+H), int(X):int(X+W)]

        resize = iaa.Resize({"height": 224, "width": 224})

        img_resize = resize(images=img)

        image_path = img_resize.reshape(img_resize.shape[0], img_resize.shape[1], 1)
        image_path = image_path.transpose((2, 0, 1))
        image_path = ((image_path.astype(np.float32))/255) - 0.5

        image_tensor = torch.tensor(image_path).to(torch.float32)
        return image_tensor

    def __len__(self) -> int:
        return len(self.image_paths)

custom = CustomDataset()
custom_loader = DataLoader(custom, batch_size = 1)

for i in range(5, 10):
  face = cv2.imread("/content/drive/MyDrive/194/" + img_filenames[i])
  print(face.shape)
  implot = plt.imshow(face[:,:,0], cmap = "gray")
  xs = []
  ys = []
  for pt in preds[i]:
      xs.append(pt[0])
      ys.append(pt[1])

  print(xs)
  plt.scatter(xs, ys, c = 'r', s= 10)


  plt.show()

import torch
model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',
    in_channels=3, out_channels=68, init_features=16, pretrained=False)

print(model)

#applies gaussian filter to blur images
def get_gaussian_kernel_2d(ksize, sigma):
    k1d = cv2.getGaussianKernel(ksize=ksize, sigma=sigma)
    return k1d * k1d.T

import cv2
gaussian_kernel = get_gaussian_kernel_2d(17, 3)
# plt.imshow(img_blur, cmap="gray");

import matplotlib
import matplotlib.pyplot as plt

plt.imshow(gaussian_kernel)

import scipy.signal as signal

#applies gaussian kernel to each of label pts, adjusting fot points off the grid
def get_gaussian_label(image, label, bbox):
  X, Y, W, H = bbox
  if X < 0:
    X = 0

  if Y < 0:
    Y = 0
  label_gaussians = []
  for pt in label:
    plot = np.zeros((224, 224))
    x = int(224*pt[0])
    y = int(224*pt[1])

    new_x = int(x - X)
    new_y = int(y - Y)
    # print("newx, newy", new_x, new_y)
    beg_x = int(max(0, new_x - 3))
    beg_y = int(max(0, new_y - 3))
    end_x = int(min(224, new_x + 3))
    end_y = int(min(224, new_y + 3))
    # print("help")
    print(beg_x, end_x, beg_y, end_y)
    x_s = end_x - beg_x + 1
    y_s = end_y - beg_y + 1
    # print("xs, ys", x_s, y_s)

    plot[beg_y: beg_y + y_s, beg_x: beg_x + x_s] = gaussian_kernel
    label_gaussians.append(plot)
  print(label_gaussians)
  return np.sum(label_gaussians)



class HeatmapTrainDataset(Dataset):
    def __init__(self):
        
        self.image_paths = img_filenames
        self.label_paths = landmarks
        self.bound_boxes = bboxes
        # TODO: Iterate over files in dataset path, add image and label paths to lists.
        # TODO: Randomly split into train and test partitions. Make sure the random split is the same each time.

        assert len(self.image_paths) == len(self.label_paths)

    def __getitem__(self, index: int):
        image_path = self.image_paths[index]
        label_path = self.label_paths[index]
        bbox_path = self.bound_boxes[index]

        img = cv2.imread("/content/drive/MyDrive/194/" + image_path)
        
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        plt.imshow(img, cmap = "gray")


        # img = ((img.astype(np.float32))/255) - 0.5

        X, Y, W, H = bbox_path

        if X < 0:
          X = 0

        if Y < 0:
          Y = 0

        # for x, subtract the bbox left value, divide by the width of the bounding box; 
        #for y, subtract bbox top and divide by the height

        img = img[int(Y):int(Y+H), int(X):int(X+W)]


        # for i in range(len(label_path)):
        #   x, y = label_path[i]
        #   x = (x - X) / W
        #   y = (y - Y) / H
        #   label_path[i] = x, y
        label_path =(label_path - np.array([X,Y]))
        # print(label_path)


        label_path = label_path.reshape((1, 68, 2))
        # print(img.shape)

        # print(label_path_resize)
        
        seq = iaa.SomeOf(2, 
                [iaa.AdditiveGaussianNoise(scale=0.05*255),
                iaa.Affine(translate_px={"x": (-10, 10)}),
                iaa.Affine(rotate = (-15, 15)),
                iaa.Fliplr(1)#,
                # iaa.Sharpen(alpha=0.5),
                ])
        
        images_aug, points_aug = seq(images=img, keypoints=label_path)
        # print(points_aug)

        resize = iaa.Resize({"height": 224, "width": 224})

        img_resize, label_path_resize = resize(images=images_aug, keypoints=points_aug)


        label_path_resize = np.divide(label_path_resize, [224, 224])

        
        
        label_path = label_path_resize.reshape((68, 2))

        # print(label_path)
        # label_path = label_path_resize.reshape((68, 2))


        # image_path = img_resize.reshape(img_resize.shape[0], img_resize.shape[1], 1)
        image_path = img_resize.reshape(img_resize.shape[0], img_resize.shape[1], 1)
        image_path = image_path.transpose((2, 0, 1))
        image_path = ((image_path.astype(np.float32))/255) - 0.5
        
        img_labels = get_gaussian_label(image_path, label_path, bbox_path)
        plt.imshow(img_labels, cmap = "gray")

        image_tensor = torch.tensor(image_path).to(torch.float32)
        label_tensor = torch.tensor(img_labels).to(torch.float32)
        # label_tensor = torch.reshape(label_tensor, (136, 1))
        return image_tensor, label_tensor
        

    def __len__(self) -> int:
        return len(self.image_paths)

heatmaps = HeatmapTrainDataset()
heatmaps_train = torch.utils.data.Subset(heatmaps,np.arange(0,500))

# test_small_set = torch.utils.data.Subset(test_data,np.arange(0,10))
heatmaps_loader = DataLoader(heatmaps_train, batch_size = 1)

criterion = nn.MSELoss()  # nn.MSELoss() nn.L1Loss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)

num_epochs = 15
loss_values = []
valid_loss_values = []

for epoch in range(num_epochs):  

    # running_losses = []
    running_loss = 0.0
    valid_running_loss = 0.0
    progress_bar = tqdm.tqdm(train_loader, position = 0, leave = True)
    valid_progress_bar = tqdm.tqdm(validation_loader, position = 0, leave = True)
    model.train()
    
    for i, data in enumerate(progress_bar):

        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        inputs = inputs.cuda()
        labels = labels.cuda()

        print(labels.shape)
        
        # zero the parameter gradients
        model.zero_grad()
        
        # forward pass
        #get maximum value coordinate for heatmap output
        outputs = np.argmax(model(inputs))

        # compute loss
        loss = criterion(outputs, labels[:,:,0])

        # backward pass
        loss.backward()

        # update network parameters
        optimizer.step()

        progress_bar.set_description(f"Train Loss: {loss}")

        # print statistics
        # running_losses.append(loss.item())
        print("epoch", epoch)
        
        loss = loss.detach()

        running_loss += loss.cpu().detach().numpy()


        
        # global_step = epoch * len(train_loader) + i
        # tb_writer.add_scalar("training loss", loss.item(), global_step)
        # progress_bar.set_description(f"Loss: {loss}")

    loss_values.append(running_loss / (i + 1))

    
    model.eval()
  #   running_losses = []

  #   model.train()
    for i, data in enumerate(valid_progress_bar):
      inputs, labels = data
      inputs = inputs.cuda()
      labels = labels.cuda()
            
  #           # calculate outputs
      outputs = model(inputs)
  # #             print(inputs.size)

  #           # compute loss
      loss = criterion(outputs, labels[:,:,0])
  # #             print(loss)
  #     loss = loss.detach().cpu().numpy()
      valid_progress_bar.set_description(f"Validation Loss: {loss}")

  #           # print statistics
  #     running_losses.append(loss.item())

      valid_running_loss += loss.cpu().detach().numpy()




    valid_loss_values.append((valid_running_loss / (i+1)))

      
# # state_dict = torch.load(os.path.join(save_dir, 'checkpoint.pt'))
# # model.load_state_dict(state_dict)

  

print('Finished Training')
# loss_values = loss_values.cpu()
# valid_loss_values= valid_loss_values.cpu()
plt.plot(loss_values, label='training loss')
plt.plot(valid_loss_values, label='validation loss')

plt.ylabel('MSE Loss')
plt.xlabel('Epoch #')